{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red26\green23\blue24;\red19\green156\blue235;\red0\green0\blue0;
}
{\*\expandedcolortbl;;\cssrgb\c13725\c12157\c12549;\cssrgb\c0\c67843\c93725;\cssrgb\c0\c0\c0;
}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f0\fs26\fsmilli13333 \cf2 \expnd0\expndtw0\kerning0
there are two types of parallelism: data parallelism and task parallelism. 
\b \cf3 Data parallelism 
\b0 \cf2 focuses on distributing subsets of the same data across multiple computing cores and performing the same operation on each core. Consider, for example, summing the contents of an array of size 
\i \cf2 N
\i0 \cf2 . On a single-core system, one thread would simply sum the elements [0] . . . [
\i \cf2 N 
\f1\i0 \uc0\u8722  
\f0 \cf2 1]. On a dual-core system, however, thread 
\i \cf2 A
\i0 \cf2 , running on core 0, could sum the elements [0] . . . [
\i \cf2 N
\f1\i0 /
\f0 \cf2 2 
\f1 \cf2 \uc0\u8722  
\f0 \cf2 1] while thread 
\i \cf2 B
\i0 \cf2 , running on core 1, could sum the elements [
\i \cf2 N
\f1\i0 /
\f0 \cf2 2] . . . [
\i \cf2 N 
\f1\i0 \uc0\u8722  
\f0 \cf2 1]. The two threads would be running in parallel on separate computing cores. 
\f1\fs24 \cf4 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f0\b\fs26\fsmilli13333 \cf3 Task parallelism 
\b0 \cf2 involves distributing not data but tasks (threads) across multiple computing cores. Each thread is performing a unique operation. Different threads may be operating on the same data, or they may be operating on different data. Consider again our example above. In contrast to that situation, an example of task parallelism might involve two threads, each performing a unique statistical operation on the array of elements. The threads again are operating in parallel on separate computing cores, but each is performing a unique operation. 
\f1\fs24 \cf4 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f0\fs26\fsmilli13333 \cf2 Fundamentally, then, data parallelism involves the distribution of data across multiple cores and task parallelism on the distribution of tasks across multiple cores. In practice, however, few applications strictly follow either data or task parallelism. In most instances, applications use a hybrid of these two strategies. 
\f1\fs24 \cf4 \
}