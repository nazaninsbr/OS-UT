{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red26\green23\blue24;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c13725\c12157\c12549;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f0\fs26\fsmilli13333 \cf2 \expnd0\expndtw0\kerning0
On a system with a single computing core, concurrency merely means that the execution of the threads will be interleaved over time (Figure 4.3), because the processing core is capable of executing only one thread at a time. On a system with multiple cores, however, concurrency means that the threads can run in parallel, because the system can assign a separate thread to each core (Figure 4.4). 
\f1\fs24 \cf3 \

\f0\fs26\fsmilli13333 \cf2 Notice the distinction between 
\i\b \cf2 parallelism 
\i0\b0 \cf2 and 
\i\b \cf2 concurrency 
\i0\b0 \cf2 in this discus- sion. A system is parallel if it can perform more than one task simultaneously. In contrast, a concurrent system supports more than one task by allowing all the tasks to make progress. Thus, it is possible to have concurrency without parallelism. 
\f1\fs24 \cf3 \
}